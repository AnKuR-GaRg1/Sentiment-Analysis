{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Sentiment analysis LSTM.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPNHCs-KULq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgB6mIj0UQp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_list = drive.ListFile({'q': \"'13uceITtEknqn4WiEC9fvpttTd9mn8mSe' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sbaKIriUe4f",
        "colab_type": "code",
        "outputId": "2e935e40-c690-4e9b-f9a6-53066094e9ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1055
        }
      },
      "source": [
        "train_downloaded = drive.CreateFile({'id': '106i86-VEOKrKWdT6xRHmX2tVfIe413rq'})\n",
        "train_downloaded.GetContentFile('train.csv')\n",
        "test_downloaded = drive.CreateFile({'id': '1prpU3Z6pHHRpB5T4XvYBPkGzcz3FMU8a'})\n",
        "test_downloaded.GetContentFile('test.csv')\n",
        "sample_downloaded = drive.CreateFile({'id': '1NnSvlLJTxQJnGGKHgbT8DYN7jWqQaaQl'})\n",
        "sample_downloaded.GetContentFile('sample.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ApiRequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchMetadata\u001b[0;34m(self, fields, fetch_all)\u001b[0m\n\u001b[1;32m    236\u001b[0m                                                  fields=fields)\\\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 404 when requesting https://www.googleapis.com/drive/v2/files/106i86-VEOKrKWdT6xRHmX2tVfIe413rq?alt=json returned \"File not found: 106i86-VEOKrKWdT6xRHmX2tVfIe413rq\">",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mApiRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4e4d2d41d44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_downloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'106i86-VEOKrKWdT6xRHmX2tVfIe413rq'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_downloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_downloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'1prpU3Z6pHHRpB5T4XvYBPkGzcz3FMU8a'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_downloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msample_downloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'1NnSvlLJTxQJnGGKHgbT8DYN7jWqQaaQl'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mGetContentFile\u001b[0;34m(self, filename, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/auth.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGet_Http_Object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchMetadata\u001b[0;34m(self, fields, fetch_all)\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mApiRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mApiRequestError\u001b[0m: <HttpError 404 when requesting https://www.googleapis.com/drive/v2/files/106i86-VEOKrKWdT6xRHmX2tVfIe413rq?alt=json returned \"File not found: 106i86-VEOKrKWdT6xRHmX2tVfIe413rq\">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVJnbioWUkKR",
        "colab_type": "code",
        "outputId": "fb81ac4f-fe9b-4f22-ba26-ff07f3c72b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "import warnings; warnings.simplefilter('ignore')\n",
        "import pickle\n",
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import time\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "import pandas as pd \n",
        "import re\n",
        "import numpy as np\n",
        "#from gensim.models import Doc2Vec, doc2vec\n",
        "from nltk.corpus import stopwords\n",
        "#from textblob import TextBlob, Word\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import backend\n",
        "backend.tensorflow_backend._get_available_gpus()\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPdSSHPwUrSn",
        "colab_type": "code",
        "outputId": "e9461c21-a243-4b7d-fc5e-b488269fa0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "tick = time.time()\n",
        "df = pd.read_csv(\"train.csv\", dtype={\"label\": object, \"text\": object})\n",
        "y = df.label \n",
        "text = df.text\n",
        "\n",
        "print(df)\n",
        "#Convert all text to lower case\n",
        "text = text.apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "\n",
        "#Remove all punctuation\n",
        "for i in range(0, len(text)):\n",
        "    text[i] = re.sub(r'[^\\w\\s]', \"\", text[i])\n",
        "    \n",
        "#for index,row in df.iterrows():\n",
        "#    if df.iloc[index]['text'] == 'My husband and I had not purchased a home before and we definitely needed some hand holding. They were patient and professional. We got our dream home and the entire experience was awesome! Thank you so much ladies for a job well done!':\n",
        "#        df.drop(index, inplace=True)\n",
        "\n",
        "#Remove stop words (removes important words! needs modification)\n",
        "stop = stopwords.words(\"english\")\n",
        "stop = stop[:143]\n",
        "stop.remove(\"not\")\n",
        "stop.remove(\"against\")\n",
        "stop.remove(\"no\")\n",
        "#stop.append(\"My husband and I had not purchased a home before and we definitely needed some hand holding. They were patient and professional. We got our dream home and the entire experience was awesome! Thank you so much ladies for a job well done! \")\n",
        "text = text.apply(lambda x: \" \".join(x for x in str(x).split() if x not in stop))\n",
        "\n",
        "#Lemmatize (not working)\n",
        "#text = text.apply(lambda x: \" \".join(Word(x).lemmatize() for x in x.split()))\n",
        "\n",
        "#Stemming\n",
        "\n",
        "#text.drop(\"My husband and I had not purchased a home before and we definitely needed some hand holding. They were patient and professional. We got our dream home and the entire experience was awesome! Thank you so much ladies for a job well done!\")\n",
        "#seperating words into lists\n",
        "for i, line in enumerate(text):\n",
        "    text[i] = line.split()\n",
        "#print(text)\n",
        "#df.text = text\n",
        "#text = list(text)\n",
        "print(time.time() - tick)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6f44ae55ea48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File b'train.csv' does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlLdyXcOU5LO",
        "colab_type": "code",
        "outputId": "9293eab7-24da-4723-db1e-602cfb901128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1094
        }
      },
      "source": [
        "X = text\n",
        "\n",
        "Y = df['label']\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         [great, mobile, app, nice, reward, program, ma...\n",
              "1         [really, fast, polite, definitely, recommend, ...\n",
              "2         [place, always, amazing, friendly, staff, grea...\n",
              "3         [wine, 101, class, friday, night, cool, spot, ...\n",
              "4         [rounding, think, place, may, potential, coupl...\n",
              "5         [romantic, tryst, planet, hollywood, poker, ro...\n",
              "6         [got, color, haircut, finally, months, looking...\n",
              "7         [never, go, place, nearly, empty, 430, pm, sat...\n",
              "8         [ive, come, 2, years, nps, bought, staff, alwa...\n",
              "9         [07082014, war, ich, mit, 5, kollegen, mittags...\n",
              "10        [5, stars, takeout, not, recommended, dinein, ...\n",
              "11        [nachdem, wir, jetzt, das, dritte, mal, vor, d...\n",
              "12        [hands, best, polish, boy, sandwich, cleveland...\n",
              "13        [oh, fuzzys, begin, familiar, toby, keith, son...\n",
              "14        [ive, tried, many, cupcakes, magnolia, prarie,...\n",
              "15        [put, irish, pub, walmart, youd, get, dont, ge...\n",
              "16        [amazing, pho, almost, drinking, broth, straw,...\n",
              "17        [la, eiffel, tower, en, las, vegaspostaes, eso...\n",
              "18        [love, shop, best, retro, dress, vegas, girls,...\n",
              "19        [definitely, sexy, show, surprisingly, funny, ...\n",
              "20        [something, must, gone, horribly, wrong, since...\n",
              "21        [happy, find, silk, found, nicole, professiona...\n",
              "22        [good, gets, qdoba, seriously, qdoba, good, ta...\n",
              "23        [another, one, favorite, spots, place, awesome...\n",
              "24        [count, charlestons, topnotch, food, service, ...\n",
              "25        [amazing, place, went, massage, relaxing, staf...\n",
              "26        [man, oh, man, place, fucking, bomb, pastor, a...\n",
              "27        [great, food, big, portions, excellent, custom...\n",
              "28        [sons, iphone, 6, screen, busted, fixed, less,...\n",
              "29        [yes, space, cozy, comfy, food, le, club, chas...\n",
              "                                ...                        \n",
              "399971    [came, 12pm, tuesday, theyre, supposed, open, ...\n",
              "399972    [pizza, place, delicious, daughters, loved, bi...\n",
              "399973    [love, place, waiting, row, half, hour, defini...\n",
              "399974    [walk, place, 5, days, week, since, november, ...\n",
              "399975    [dont, usually, write, 1, stars, moira, deserv...\n",
              "399976    [mediocre, food, overpriced, buffet, come, sus...\n",
              "399977    [food, fantastic, though, pricier, side, brunc...\n",
              "399978    [service, ok, c, 25, food, quick, arrive, wait...\n",
              "399979    [las, vegas, past, weekend, attend, mountain, ...\n",
              "399980    [whatever, need, done, subaru, guys, reliable,...\n",
              "399981    [fantastic, experience, room, indeed, whole, h...\n",
              "399982    [well, first, official, verizon, wireless, sto...\n",
              "399983    [got, vanilla, spiced, oatmeal, 8, like, 4, sl...\n",
              "399984    [place, delightful, food, elegant, tasteful, a...\n",
              "399985    [stayed, several, times, management, staff, po...\n",
              "399986    [great, chinese, food, great, place, take, fri...\n",
              "399987    [never, 188, forever, continue, coming, back, ...\n",
              "399988    [perfectly, adequate, gyros, place, small, cle...\n",
              "399989    [ive, used, mbv, least, nine, years, fix, 2000...\n",
              "399990    [dont, bother, coming, back, hadnt, 10, years,...\n",
              "399991    [couldnt, happier, 5th, wine, first, introduce...\n",
              "399992    [kasadee, fantastic, hair, stylist, best, ive,...\n",
              "399993    [decided, grab, food, fish, chips, thought, no...\n",
              "399994    [hot, dogs, 1218, inches, great, frozen, hot, ...\n",
              "399995    [never, used, moving, company, prior, family, ...\n",
              "399996    [went, first, time, got, kelsey, dye, cut, hai...\n",
              "399997    [first, experience, true, food, kitchen, trip,...\n",
              "399998    [must, one, talkedabout, secondhand, bike, pla...\n",
              "399999    [undeniably, best, bang, buck, city, 10, bucks...\n",
              "400000    [dont, order, hamburgers, ordered, well, done,...\n",
              "Name: text, Length: 400001, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyqfJ4RCXJTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB8gRYsFXLhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 20000\n",
        "#tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6bt3WNUXNlY",
        "colab_type": "code",
        "outputId": "a3082045-b988-4bc1-a65e-7b89b6c3859f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "X = tokenizer.texts_to_sequences(text)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "\n",
        "Y = pd.get_dummies(y.values)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "print(y.values)\n",
        "print(Y_train.values)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320000, 571) (320000, 3)\n",
            "(80001, 571) (80001, 3)\n",
            "['1' '2' '2' ... '2' '2' '0']\n",
            "[[0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " ...\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEwsICECXWDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 100\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrRqxUQlXmXf",
        "colab_type": "code",
        "outputId": "272f1fce-4cc9-4c44-a0f5-4006bc6c8bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "Y_train, Y_test = train_test_split(Y, test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "print(y.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320000, 571) (320000, 3)\n",
            "(80001, 571) (80001, 3)\n",
            "['1' '2' '2' ... '2' '2' '0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i_VKEzbX0c1",
        "colab_type": "code",
        "outputId": "931d4d29-af5a-4fa6-aa62-8a9aa80f84d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "\n",
        "\n",
        "inp = Input(shape=(maxlen, ))\n",
        "embed_size = 128\n",
        "x = Embedding(max_features, embed_size)(inp)\n",
        "x = LSTM(200, return_sequences=True,name='lstm_layer')(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(120, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(60, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(4, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 100, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "lstm_layer (LSTM)            (None, 100, 200)          263200    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 120)               24120     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 60)                7260      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 4)                 244       \n",
            "=================================================================\n",
            "Total params: 2,854,824\n",
            "Trainable params: 2,854,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDYKbyEOX23I",
        "colab_type": "code",
        "outputId": "fbb1bcd9-35cb-4692-9f69-77cbfdbb3515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "print(\"start fitting...\")\n",
        "model.fit(X_t, y_train , epochs=3, batch_size=32, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start fitting...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-1d10e6732eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start fitting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_13 to have shape (1,) but got array with shape (3,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RAYLnkpX53p",
        "colab_type": "code",
        "outputId": "9de00fe2-df56-4453-e774-26374e28870b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "scores = model.evaluate(X_te, y_test)\n",
        "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "y_pred = model.predict(X_te, batch_size=1024)\n",
        "y_classes = y_pred.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80001/80001 [==============================] - 146s 2ms/step\n",
            "\n",
            "acc: 90.4376%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwnaxZiowMyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z=np.array(y_test)\n",
        "d=y_test.astype(int)\n",
        "d\n",
        "z=np.array(d)\n",
        "z[0]\n",
        "Y_TEST=z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Q7yj45x0jT",
        "colab_type": "code",
        "outputId": "032b9c02-d8bc-4674-ddd1-db81a8d68848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "\n",
        "accScore = metrics.accuracy_score(Y_TEST,y_classes)\n",
        "\n",
        "lbl = [0,1,2]\n",
        "precision = metrics.precision_score(Y_TEST,y_classes,average=None,labels=lbl)\n",
        "recall = metrics.recall_score(Y_TEST,y_classes,average=None,labels=lbl)\n",
        "f1Score = metrics.f1_score(Y_TEST,y_classes,average=None,labels=lbl)\n",
        "\n",
        "print(\"\\nOverall Acurracy: \",accScore,\"\\n\")\n",
        "\n",
        "for i in range(len(lbl)):\n",
        "    print(\"Precision of %s class: %f\" %(lbl[i],precision[i]))\n",
        "    print(\"Recall of %s class: %f\" %(lbl[i],recall[i]))\n",
        "    print(\"F1-Score of %s class: %f\" %(lbl[i],f1Score[i]),\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Overall Acurracy:  0.9043761952975587 \n",
            "\n",
            "Precision of 0 class: 0.910162\n",
            "Recall of 0 class: 0.876813\n",
            "F1-Score of 0 class: 0.893176 \n",
            "\n",
            "Precision of 1 class: 0.780361\n",
            "Recall of 1 class: 0.712560\n",
            "F1-Score of 1 class: 0.744921 \n",
            "\n",
            "Precision of 2 class: 0.932406\n",
            "Recall of 2 class: 0.965425\n",
            "F1-Score of 2 class: 0.948628 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mGlszdzx3Pb",
        "colab_type": "code",
        "outputId": "80fdb3ff-a8a5-48e0-800c-9a67f3bcb8c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "import utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-69d9c258b31d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJtPOD5zpkMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding, Flatten\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "kernel_size=3\n",
        "embedding_matrix = np.random.randn(20000, 128) * 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOgR_M4PBJlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = Input(shape=(100, ))\n",
        "embed_size = 128\n",
        "x = Embedding(20000,128,weights=[embedding_matrix])(inp)#input_length=maxlen)(inp)\n",
        "x=(Dropout(0.4))(x)\n",
        "x=(Conv1D(600, kernel_size, padding='valid', activation='relu', strides=1))(x)\n",
        "x=(Conv1D(300, kernel_size, padding='valid', activation='relu', strides=1))(x)\n",
        "x=(Conv1D(150, kernel_size, padding='valid', activation='relu', strides=1))(x)\n",
        "x=(Conv1D(75, kernel_size, padding='valid', activation='relu', strides=1))(x)\n",
        "x=(Flatten())(x)\n",
        "x=(Dense(600))(x)\n",
        "x=(Dropout(0.5))(x)\n",
        "x=(Activation('relu'))(x)\n",
        "x=(Dense(1))(x)\n",
        "x=(Activation('softmax'))(x)\n",
        "model=Model(inputs=inp, outputs=x)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-kfwxG2CTqM",
        "colab_type": "code",
        "outputId": "92a27b88-2057-47a8-ac82-46c8c4e94d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 100, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 98, 600)           231000    \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 96, 300)           540300    \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 94, 150)           135150    \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 92, 75)            33825     \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 6900)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 600)               4140600   \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 601       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 7,641,476\n",
            "Trainable params: 7,641,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpSKbkAdCuZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}